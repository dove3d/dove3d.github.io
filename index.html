<script src="https://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
	<title>&#128330; DOVE: Learning Deformable 3D Objects by Watching Videos</title>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
        if you update and want to force Facebook to re-scrape. -->
	<meta property="og:image" content="https://dove3d.github.io/resources/og_image.jpg"/>
	<meta property="og:title" content="DOVE: Learning Deformable 3D Objects by Watching Videos." />
	<meta property="og:description" content="We propose a method for learning deformable 3D birds from videos, without keypoint, viewpoint or template shape supervision." />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="summary" />
    <meta property="twitter:title"         content="DOVE: Learning Deformable 3D Objects by Watching Videos." />
    <meta property="twitter:description"   content="We propose a method for learning deformable 3D birds from videos, without keypoint, viewpoint or template shape supervision." />
    <meta property="twitter:image"         content="https://dove3d.github.io/resources/og_image.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    
    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=G-LDZDB316TT"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'G-LDZDB316TT');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
        &#128330; DOVE: Learning Deformable 3D Objects by Watching Videos
    </div>

    <div class="venue">
        arXiv preprint
    </div>

    <br><br>

    <div class="author">
        <a href="https://elliottwu.com">Shangzhe Wu</a>*
    </div>
    <div class="author">
        <a href="https://www.robots.ox.ac.uk/~tomj">Tomas Jakab</a>*
    </div>
    <div class="author">
        <a href="https://chrirupp.github.io">Christian Rupprecht</a>
    </div>
    <div class="author">
        <a href="https://www.robots.ox.ac.uk/~vedaldi">Andrea Vedaldi</a>
    </div>

    <br><br>

    <div class="affiliation">
      Visual Geometry Group, University of Oxford
    </div>

    <br><br>

    <p style="text-align: center;">( * equal contribution )</p>

    <br>

    <div class="links"><a href="">[Paper]</a></div>
    <div class="links"><a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">[Video]</a></div>
    <div class="links">[Code coming]</div>

    <br><br>

    <video autoplay loop muted inline width="1200" style="max-width: 80%">
      <source src="./resources/teaser.mp4" type="video/mp4" alt="Teaser video">
    </video>
    <br><br>
    <p style="width: 80%;">
        <b><i>DOVE</i></b> - Deformable Objects from VidEos. Given a collection of video clips of an object category as training data, we learn a model that is able to predict a textured, articulated 3D mesh ofthe object from a single input image.
    </p>

    <br><br>
    <hr>

    <h1>Interactive Demo</h1>
    <p style="width: 80%; text-align: center;">
        <a href="demo/demo.html">Full screen version.</a>
    </p>
    <div class="video-container" style="cursor: all-scroll">
        <iframe src="demo/demo.html" style="border:0;"></iframe>
    </div>

    <hr>

    <h1>Abstract</h1>
    <p style="width: 80%;">
        Learning deformable 3D objects from 2D images is an extremely ill-posed problem. Existing methods rely on explicit supervision to establish multi-view correspondences, such as template shape models and keypoint annotations, which restricts their applicability on objects "in the wild". In this paper, we propose to use monocular videos, which naturally provide correspondences across time, allowing us to learn 3D shapes of deformable object categories without explicit keypoints or template shapes. Specifically, we present DOVE, which learns to predict 3D canonical shape, deformation, viewpoint and texture from a single 2D image of a bird, given a bird video collection as well as automatically obtained silhouettes and optical flows as training data. Our method reconstructs temporally consistent 3D shape and deformation, which allows us to animate and re-render the bird from arbitrary viewpoints from a single image.
    </p>

    <br><br>
    <hr>

    <h1>Video</h1>
    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameBorder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <br><br>
    <hr>

    <h1>Method Overview</h1>
    <img style="width: 80%;" src="./resources/method.jpg"
         alt="Method overview figure"/>
    <br>
    <p style="width: 80%;">
      Given a single frame in each training sequence, we predict the 3D pose, shape and texture of the object. Using a differentiable renderer to reconstruct the input image, the entire model can be trained end-to-end with reconstruction losses, without any explicit 3D supervision.
    </p>

    <br>
    <hr>

    <h1>Results</h1>
    <h3 style="text-align: center;">Single-Image Reconstruction</h3>
    <video autoplay loop muted inline width="1200" style="max-width: 80%">
      <source src="./resources/reconstruction.mp4" type="video/mp4" alt="Reconstruction results">
    </video>

    <br><br>

    <h3 style="text-align: center;">Texture Swapping</h3>
    <video autoplay loop muted inline width="1200" style="max-width: 80%">
      <source src="./resources/swap_tex.mp4" type="video/mp4" alt="Texture swapping results">
    </video>

    <br><br>

    <h3 style="text-align: center;">Animation</h3>
    <video autoplay loop muted inline width="1200" style="max-width: 80%">
      <source src="./resources/animation.mp4" type="video/mp4" alt="Animation results">
    </video>

    <br><br>

    <h3 style="text-align: center;">Comparisons</h3>

    <div id="carouselExampleDark" class="carousel carousel-dark slide" data-bs-ride="carousel">
        <div class="carousel-indicators">
            <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
            <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="1" aria-label="Slide 2"></button>
            <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="2" aria-label="Slide 3"></button>
            <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="3" aria-label="Slide 3"></button>
        </div>
        <div class="carousel-inner">
          <div class="carousel-item active">
            <video autoplay loop muted inline width="1200" style="max-width: 80%">
            <source src="./resources/compare1.mp4" type="video/mp4" alt="Comparison results">
            </video>
          </div>

          <div class="carousel-item">
            <video autoplay loop muted inline width="1200" style="max-width: 80%">
            <source src="./resources/compare2.mp4" type="video/mp4" alt="Comparison results">
            </video>
          </div>

          <div class="carousel-item">
            <video autoplay loop muted inline width="1200" style="max-width: 80%">
            <source src="./resources/compare3.mp4" type="video/mp4" alt="Comparison results">
            </video>
          </div>

          <div class="carousel-item">
            <video autoplay loop muted inline width="1200" style="max-width: 80%">
            <source src="./resources/compare4.mp4" type="video/mp4" alt="Comparison results">
            </video>
          </div>
        
        </div>
        <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="prev">
          <span class="carousel-control-prev-icon" aria-hidden="true"></span>
          <span class="visually-hidden">Previous</span>
        </button>
        <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="next">
          <span class="carousel-control-next-icon" aria-hidden="true"></span>
          <span class="visually-hidden">Next</span>
        </button>
      </div>

    <br><br>
    <hr>

    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org">
            <img class="layered-paper-big" width="100%" src="./resources/paper.jpg" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>DOVE: Learning Deformable 3D Objects by Watching Videos</h3>
        <p>Shangzhe Wu*, Tomas Jakab*, Christian Rupprecht, Andrea Vedaldi</p>
        <p>(*equal contribution)</p>
        <p>arXiv preprint, 2021.</p>
        <pre><code>@Article{wu2021dove,
    title = {{DOVE}: Learning Deformable 3D Objects by Watching Videos},
    author = {Shangzhe Wu and Tomas Jakab and Christian Rupprecht and Andrea Vedaldi},
    journal = {arXiv preprint arXiv:xxxx.xxxxx},
    year = {2021},
}</code></pre>
    </div>

    <br><br>
    <hr>

    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        We thank Xueting Li for sharing the code for VMR with us. Shangzhe Wu is supported by Facebook Research. Tomas Jakab is supported by Clarendon Scholarship. Christian Rupprecht is supported by Innovate UK (project 71653) on behalf of UK Research and Innovation (UKRI) and by the European Research Council (ERC) IDIU-638009. Andrea Vedaldi is supported by European Research Council (ERC) IDIU-638009.
        This <a href="https://github.com/elliottwu/webpage-template">webpage template</a> was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
        and <a href="http://richzhang.github.io/">Richard Zhang</a> for a
        <a href="http://richzhang.github.io/colorization/">colorful</a> project.
    </p>

    <br><br>
</div>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js" integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF" crossorigin="anonymous"></script>

</body>

</html>
